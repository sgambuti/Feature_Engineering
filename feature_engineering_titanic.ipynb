{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgambuti/Feature_Engineering/blob/main/feature_engineering_titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "jeKk72Wz2cyG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "Yxg712fI2j0d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zU1PEPmyndiM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import feature\n",
        "from pyspark.ml import classification\n",
        "from pyspark.sql import functions as fn\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, \\\n",
        "    MulticlassClassificationEvaluator, \\\n",
        "    RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "VeI2UYIDndiP",
        "outputId": "e336723d-9685-43b8-f1ad-a24d46fd53b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2e5ef979c37d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/titanic_original.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.0-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/content/datasets/titanic_original.csv;"
          ]
        }
      ],
      "source": [
        "titanic_df = spark.read.csv('datasets/titanic_original.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGlgjgdRndiQ"
      },
      "outputs": [],
      "source": [
        "titanic_df.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHzg6kf7ndiR"
      },
      "outputs": [],
      "source": [
        "# some basic cleanup\n",
        "drop_cols = ['boat', 'body']\n",
        "new_titanic_df = titanic_df.\\\n",
        "    drop(*drop_cols).\\\n",
        "    withColumnRenamed('home.dest', 'home_dest').\\\n",
        "    fillna('O').\\\n",
        "    dropna(subset=['pclass', 'age', 'sibsp', 'parch', 'fare', 'survived'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Wm4-CSTfndiS"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBsANIaCndiS"
      },
      "outputs": [],
      "source": [
        "training, test = new_titanic_df.randomSplit([0.8, 0.2], 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXfK2G1EndiT"
      },
      "source": [
        "## classic pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osVHSn1UndiV"
      },
      "outputs": [],
      "source": [
        "model0 = Pipeline(stages=[feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare'],\n",
        "                                        outputCol='features'),\n",
        "                 classification.LogisticRegression(labelCol='survived', featuresCol='features')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtLj_HUandiV"
      },
      "outputs": [],
      "source": [
        "model0_fitted = model0.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2Z165CundiW"
      },
      "outputs": [],
      "source": [
        "model0_fitted.transform(test).select(fn.avg(fn.expr('prediction = survived').cast('float'))).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxyBCAmnndiX"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.select(fn.avg('survived')).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u6-q1dHndiY"
      },
      "outputs": [],
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol='survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rCUvziLndiY"
      },
      "outputs": [],
      "source": [
        "evaluator.evaluate(model0_fitted.transform(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-Wyj4ondiZ"
      },
      "source": [
        "If we wanted to modify the pipeline to add \"sex\" (gender) as a feature, we need to modify the point of entry and the next transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqdmUDsandia"
      },
      "outputs": [],
      "source": [
        "model1 = Pipeline(stages=[feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare'],\n",
        "                                        outputCol='features'),\n",
        "                          feature.StringIndexer(inputCol='sex', outputCol='encoded_sex'),\n",
        "                          feature.VectorAssembler(inputCols=['features', 'encoded_sex'], outputCol='final_features'),\n",
        "                 classification.LogisticRegression(labelCol='survived', featuresCol='final_features')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaOh5FAnndib"
      },
      "outputs": [],
      "source": [
        "model1_fitted = model1.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR0J3FAwndic"
      },
      "outputs": [],
      "source": [
        "evaluator.evaluate(model1_fitted.transform(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2nYjKVGndic"
      },
      "source": [
        "You can use the professor's package `pyspark_pipes` to do this more easily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VttCOeKndid"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/daniel-acuna/pyspark_pipes.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC4Dnh34ndid"
      },
      "outputs": [],
      "source": [
        "# package that makes it easy to build pipelines\n",
        "from pyspark_pipes import pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXGChRQNndid"
      },
      "outputs": [],
      "source": [
        "uber_model = pipe((feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "      feature.StringIndexer(inputCol='sex')\n",
        "     )      \n",
        "      ,\n",
        "     feature.VectorAssembler(),\n",
        "     classification.LogisticRegression(labelCol='survived'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCkqtSOxndie"
      },
      "outputs": [],
      "source": [
        "uber_model_fitted = uber_model.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCGgFQ0nndie"
      },
      "outputs": [],
      "source": [
        "uber_model_fitted.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHgTMlAH0yWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyA8LPKgndif"
      },
      "source": [
        "# Automated evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RrkBeEFndif"
      },
      "outputs": [],
      "source": [
        "def binary_evaluation(model_pipeline, model_fitted, data):\n",
        "    return BinaryClassificationEvaluator(labelCol=model_pipeline.getStages()[-1].getLabelCol(), \n",
        "                                rawPredictionCol=model_pipeline.getStages()[-1].getRawPredictionCol()).\\\n",
        "    evaluate(model_fitted.transform(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHQiycuendif"
      },
      "source": [
        "# Initial model\n",
        "\n",
        "$$\n",
        "p(survived = 1) = f(\\text{pclass}, \\text{age}, \\text{sibsp}, \\text{parch}, \\text{fare})\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjkmBd17ndig"
      },
      "outputs": [],
      "source": [
        "model1_pipeline = pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "             classification.LogisticRegression(labelCol='survived'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IdnuWI_ndig"
      },
      "outputs": [],
      "source": [
        "model1_fitted = model1_pipeline.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isEdvPFWndig"
      },
      "outputs": [],
      "source": [
        "binary_evaluation(model1_pipeline, model1_fitted, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LZ6cdGQndih"
      },
      "outputs": [],
      "source": [
        "model1_fitted.stages[-1].coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7WkWP1Mndih"
      },
      "outputs": [],
      "source": [
        "model1_fitted.stages[-1].intercept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Nq1J23ndii"
      },
      "source": [
        "# Some preprocessing of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-915X_Wndii"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(new_titanic_df.toPandas()[['pclass', 'age', 'sibsp', 'parch', 'fare']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEMITstndij"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlDLti2gndij"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.DataFrame(np.vstack(pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "    feature.StandardScaler(withMean=True)).fit(new_titanic_df).transform(new_titanic_df).toPandas().iloc[:, -1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBeBjM1dndik"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.toPandas()[['pclass', 'age', 'sibsp', 'parch', 'fare']].age.hist()\n",
        "plt.xlabel('age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u_-OkwVndil"
      },
      "outputs": [],
      "source": [
        "d = pd.DataFrame(np.vstack(pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "    feature.StandardScaler(withMean=True)).fit(new_titanic_df).transform(new_titanic_df).toPandas().iloc[:, -1]))\n",
        "d.columns = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
        "d.age.hist()\n",
        "plt.xlabel('age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg6qL7RUndil"
      },
      "source": [
        "## Initial model on standardized results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vRAlCdsndil"
      },
      "outputs": [],
      "source": [
        "model2_pipeline = pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "              feature.StandardScaler(withMean=True),\n",
        "             classification.LogisticRegression(labelCol='survived'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bFT-Yeqndim"
      },
      "outputs": [],
      "source": [
        "model2_fitted = model2_pipeline.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZJniLH-ndim"
      },
      "outputs": [],
      "source": [
        "binary_evaluation(model1_pipeline, model1_fitted, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOK2Lr_Kndim"
      },
      "outputs": [],
      "source": [
        "binary_evaluation(model2_pipeline, model2_fitted, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgIaUMxundin"
      },
      "outputs": [],
      "source": [
        "model2_fitted.stages[-1].intercept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLFlLZ3endin"
      },
      "outputs": [],
      "source": [
        "model2_fitted.stages[-1].coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2k06zFgndio"
      },
      "source": [
        "## other scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I548GHj0ndio"
      },
      "outputs": [],
      "source": [
        "d = pd.DataFrame(np.vstack(pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "    feature.MaxAbsScaler()).fit(new_titanic_df).transform(new_titanic_df).toPandas().iloc[:, -1]))\n",
        "d.columns = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
        "d.age.hist()\n",
        "plt.xlabel('age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwSxysHZndio"
      },
      "source": [
        "# Bucketizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9fQNXosndip"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.toPandas()[['pclass', 'age', 'sibsp', 'parch', 'fare']].fare.hist()\n",
        "plt.xlabel('fare')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLvPUzfwndip"
      },
      "outputs": [],
      "source": [
        "feature.Bucketizer(splits=[0, 20, 50, 100, 400, 800], inputCol='fare').transform(new_titanic_df).toPandas().iloc[:, -1].hist()\n",
        "plt.xticks([-1, 0, 1, 2, 3, 4, 5]);\n",
        "plt.xlabel('Fare bucket')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZuNrvWjndip"
      },
      "outputs": [],
      "source": [
        "qd = feature.QuantileDiscretizer().setNumBuckets(4).setInputCol(\"fare\").setOutputCol(\"result\").fit(new_titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgdBczwMndiq"
      },
      "outputs": [],
      "source": [
        "qd.getSplits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQHTpRhmndiq"
      },
      "outputs": [],
      "source": [
        "feature.QuantileDiscretizer().setNumBuckets(4).setInputCol(\"fare\").setOutputCol(\"result\").fit(new_titanic_df).transform(new_titanic_df).toPandas().iloc[:, -1].hist()\n",
        "plt.xticks([-1, 0, 1, 2, 3, 4, 5]);\n",
        "plt.xlabel('Fare quantiles')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlFgtPlandiq"
      },
      "outputs": [],
      "source": [
        "d = pd.DataFrame(np.vstack(pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch', 'fare']),\n",
        "    feature.MaxAbsScaler()).fit(new_titanic_df).transform(new_titanic_df).toPandas().iloc[:, -1]))\n",
        "d.columns = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
        "d.age.hist()\n",
        "plt.xlabel('age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2QhJjRhndir"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.toPandas().age.hist()\n",
        "plt.xlabel('age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZcg3Dj3ndir"
      },
      "outputs": [],
      "source": [
        "# full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDlaYc02ndir"
      },
      "outputs": [],
      "source": [
        "gender_pipe = feature.StringIndexer(inputCol='sex', handleInvalid='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zer1KBlndis"
      },
      "outputs": [],
      "source": [
        "titles_list = \" Capt  Col  Don  Dona  Dr  Jonkheer  Lady  Major  Master  Miss  Mlle  Mme  Mr  Mrs  Ms  Rev  Sir\".lower().split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDI-D_f7ndis"
      },
      "outputs": [],
      "source": [
        "title_pipe = pipe(feature.RegexTokenizer(pattern=\"\\\\b(\" + (\"|\".join(titles_list)) + \")\\\\b\", \n",
        "                       gaps=False,\n",
        "                      inputCol='name'), \n",
        "                  feature.CountVectorizer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXUq05Ddndis"
      },
      "outputs": [],
      "source": [
        "new_titanic_df.select('embarked').distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOH9BHafndit"
      },
      "outputs": [],
      "source": [
        "embarked_pipe = pipe(feature.StringIndexer(inputCol='embarked', handleInvalid='skip'), feature.OneHotEncoder())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnWKe1YRndit"
      },
      "outputs": [],
      "source": [
        "embarked_pipe.fit(new_titanic_df.select('embarked')).transform(new_titanic_df.select('embarked')).distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GbP8xFPndit"
      },
      "outputs": [],
      "source": [
        "cabin_pipe = Pipeline(stages=[feature.SQLTransformer(statement='select *, substring(cabin,1,1) as cabin_col from __THIS__'),\n",
        "                              feature.StringIndexer(inputCol='cabin_col', outputCol='cabin_col2', handleInvalid='skip'),\n",
        "                              feature.OneHotEncoder(inputCol='cabin_col2')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM0bt82kndiu"
      },
      "outputs": [],
      "source": [
        "numerical_features = pipe(feature.VectorAssembler(inputCols=['pclass', 'age', 'sibsp', 'parch']),\n",
        "                          feature.StandardScaler())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vzKbWq6ndiu"
      },
      "outputs": [],
      "source": [
        "all_features = pipe((numerical_features, feature.QuantileDiscretizer().setNumBuckets(4).setInputCol(\"fare\").setOutputCol(\"result\"), gender_pipe, title_pipe, embarked_pipe, cabin_pipe), feature.VectorAssembler())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75ifMd1ondiv"
      },
      "outputs": [],
      "source": [
        "lr = classification.LogisticRegression(labelCol='survived')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TBOqYgbndiv"
      },
      "outputs": [],
      "source": [
        "final_model_pipeline = pipe(all_features, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-0o5bIindiw"
      },
      "outputs": [],
      "source": [
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.elasticNetParam, [0., 0.01, 0.1]) \\\n",
        "    .addGrid(lr.regParam, [0.1, 0.01, 0.001, 0.0001]) \\\n",
        "    .build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcn5UeXgndiw"
      },
      "outputs": [],
      "source": [
        "len(paramGrid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULHw_FLjndix"
      },
      "outputs": [],
      "source": [
        "evaluator = BinaryClassificationEvaluator(labelCol=lr.getLabelCol(), rawPredictionCol=lr.getRawPredictionCol())\n",
        "crossval = CrossValidator(estimator=final_model_pipeline, \n",
        "                          estimatorParamMaps=paramGrid, \n",
        "                          evaluator=evaluator, \n",
        "                          numFolds=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sfohATFndix"
      },
      "outputs": [],
      "source": [
        "final_model_fitted = crossval.fit(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCj3uPQKndiy"
      },
      "outputs": [],
      "source": [
        "test.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idmxFU80ndiz"
      },
      "outputs": [],
      "source": [
        "evaluator.evaluate(final_model_fitted.transform(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4GZ5XVUndiz"
      },
      "outputs": [],
      "source": [
        "b = final_model_fitted.bestModel.stages[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM-LzFldndi0"
      },
      "outputs": [],
      "source": [
        "b.getInputCol()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IeXScobndi0"
      },
      "outputs": [],
      "source": [
        "b.getSplits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q9h8MTEndi2"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[-1].coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVLpAMoSndi3"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[0].stages[0].getInputCols()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTXZZ_tAndi3"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VQ7SQrZndi4"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[1].getInputCol()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJsWw8O4ndi4"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[1].getInputCol()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bud-d4v2ndi4"
      },
      "outputs": [],
      "source": [
        "si = final_model_fitted.bestModel.stages[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_S5WYyMndi5"
      },
      "outputs": [],
      "source": [
        "si.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpTNy_0Kndi5"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[3].stages[1].vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_t2Xj0Bndi5"
      },
      "outputs": [],
      "source": [
        "len(final_model_fitted.bestModel.stages[-1].coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdB0KU6Andi6"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBfz2Mk6ndi6"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[-1].coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brW79lMGndi6"
      },
      "outputs": [],
      "source": [
        "lr_fit = final_model_fitted.bestModel.stages[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e_CSyC4ndi6"
      },
      "outputs": [],
      "source": [
        "lr_fit.summary.featuresCol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hYLWjgEndi7"
      },
      "outputs": [],
      "source": [
        "final_model_fitted.bestModel.stages[0].stages"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "name": "feature_engineering_titanic",
    "notebookId": 4503310255797310,
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}